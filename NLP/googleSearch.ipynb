{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597560602525",
   "display_name": "Python 3.7.7 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Search Engines like Google Retrieve Results: Introduction to Information Extraction using Python and spaCy\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/09/introduction-information-extraction-python-spacy/?utm_source=blog&utm_medium=how-to-build-knowledge-graph-text-using-spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    How do search engines like Google understand our queries and provide relevant results?\n",
    "    Learn about the concept of information extraction\n",
    "    We will apply information extraction in Python using the popular spaCy library – so a lot of hands-on learning is ahead!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "I rely heavily on search engines (especially Google) in my daily role as a data scientist. My search results span a variety of queries – Python code questions, machine learning algorithms, comparison of Natural Language Processing (NLP) frameworks, among other things.\n",
    "\n",
    "I’ve always been curious about how these search engines understand my query and extract the relevant results as if they know what I am thinking.\n",
    "\n",
    "I wanted to understand how the NLP aspect works here – basically, how does the algorithm understand unstructured text data and convert that into structured data and show me relevant results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "\n",
    "    Introduction to Information Extraction\n",
    "    Semantic Relationships: Get Structured Knowledge from Unstructured Text\n",
    "    Different Approaches to Information Extraction\n",
    "        Rule-Based Approach\n",
    "        Supervised Machine Learning Approach\n",
    "        Semi-supervised Approach\n",
    "    Information Extraction using Python and spaCy\n",
    "        spaCy’s Rule-based Matching\n",
    "        Subtree Matching for Relation Extraction\n",
    "    What’s Next?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Information Extraction\n",
    "\n",
    "Information Extraction (IE) is a crucial cog in the field of Natural Language Processing (NLP) and linguistics. It’s widely used for tasks such as Question Answering Systems, Machine Translation, Entity Extraction, Event Extraction, Named Entity Linking, Coreference Resolution, Relation Extraction, etc.\n",
    "\n",
    "In information extraction, there is an important concept of triples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A triple represents a couple of entities and a relation between them. For example, (Obama, born, Hawaii) is a triple in which ‘Obama’ and ‘Hawaii’ are the related entities, and the relation between them is ‘born’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, we will focus on the extraction of these types of triples from a given text.\n",
    "\n",
    "Before moving ahead, let’s take a look at the different approaches to Information Extraction. We can broadly divide Information Extraction into two branches as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Traditional Information Extraction, the relations to be extracted are pre-defined. In this article, we will cover the rule-based methods only.\n",
    "\n",
    "In Open Information Extraction, the relations are not pre-defined. The system is free to extract any relations it comes across while going through the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Relationships: Get Structured Knowledge from Unstructured Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Approaches to Information Extraction\n",
    "\n",
    "In the previous section, we managed to easily extract triples from a few sentences. However, in the real world, the data size is huge and manual extraction of structured information is not feasible. Therefore, automating this information extraction becomes important.\n",
    "\n",
    "There are multiple approaches to perform information extraction automatically. Let’s understand them one-by-one:\n",
    "\n",
    "    Rule-based Approach: We define a set of rules for the syntax and other grammatical properties of a natural language and then use these rules to extract information from text\n",
    "    Supervised: Let’s say we have a sentence S. It has two entities E1 and E2. Now, the supervised machine learning model has to detect whether there is any relation (R) between E1 and E2. So, in a supervised approach, the task of relation extraction turns into the task of relation detection. The only drawback of this approach is that it needs a lot of labeled data to train a model\n",
    "    Semi-supervised: When we don’t have enough labeled data, we can use a set of seed examples (triples) to formulate high-precision patterns that can be used to extract more relations from the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy’s Rule-Based Matching\n",
    "\n",
    "Before we get started, let’s talk about Marti Hearst. She is a computational linguistics researcher and a professor in the School of Information at the University of California, Berkeley. How does she fit into this article? I can sense you wondering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Professor Marti has actually done extensive research on the topic of information extraction. One of her most interesting studies focuses on building a set of text-patterns that can be employed to extract meaningful information from text. These patterns are popularly known as “Hearst Patterns”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In linguistics terms, we will call “red algae” as Hypernym and “Gelidium” as its Hyponym.\n",
    "\n",
    "We can formalize this pattern as “X such as Y”, where X is the hypernym and Y is the hyponym. This was one of the many patterns from the Hearst Patterns. Here’s a list to give you an intuition behind the idea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s try to extract hypernym-hyponym pairs by using these patterns/rules. We will use spaCy’s rule-based matcher to perform this task.\n",
    "\n",
    "First, we will import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string \n",
    "import nltk \n",
    "import spacy \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math \n",
    "from tqdm import tqdm \n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "from spacy import displacy \n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "# load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all set to mine information from text based on these Hearst Patterns.\n",
    "\n",
    "    Pattern: X such as Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"GDP in developing countries such as Vietnam will continue growing at a high rate.\" \n",
    "\n",
    "# create a spaCy object \n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to pull out the desired information from the above sentence, it is really important to understand its syntactic structure – things like the subject, object, modifiers, and parts-of-speech (POS) in the sentence.\n",
    "\n",
    "We can easily explore these syntactic details in the sentence by using spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GDP --> nsubj --> NOUN\nin --> prep --> ADP\ndeveloping --> amod --> VERB\ncountries --> pobj --> NOUN\nsuch --> amod --> ADJ\nas --> prep --> SCONJ\nVietnam --> pobj --> PROPN\nwill --> aux --> VERB\ncontinue --> ROOT --> VERB\ngrowing --> xcomp --> VERB\nat --> prep --> ADP\na --> det --> DET\nhigh --> amod --> ADJ\nrate --> pobj --> NOUN\n. --> punct --> PUNCT\n"
    }
   ],
   "source": [
    "# print token, dependency, POS tag \n",
    "for tok in doc: \n",
    "  print(tok.text, \"-->\",tok.dep_,\"-->\", tok.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look around the terms “such” and “as” . They are followed by a noun (“countries”). And after them, we have a proper noun (“Vietnam”) that acts as a hyponym.\n",
    "\n",
    "So, let’s create the required pattern using the dependency tags and the POS tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the pattern \n",
    "pattern = [{'POS':'NOUN'}, \n",
    "           {'LOWER': 'such'}, \n",
    "           {'LOWER': 'as'}, \n",
    "           {'POS': 'PROPN'}] #proper noun]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s extract the pattern from the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "countries such as Vietnam\n"
    }
   ],
   "source": [
    "# Matcher class object \n",
    "matcher = Matcher(nlp.vocab) \n",
    "matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "matches = matcher(doc) \n",
    "span = doc[matches[0][1]:matches[0][2]] \n",
    "\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! It works perfectly. However, if we could get “developing countries” instead of just “countries”, then the output would make more sense.\n",
    "\n",
    "So, we will now also capture the modifier of the noun just before “such as” by using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "developing countries such as Vietnam\n"
    }
   ],
   "source": [
    "# Matcher class object\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "#define the pattern\n",
    "pattern = [{'DEP':'amod', 'OP':\"?\"}, # adjectival modifier\n",
    "           {'POS':'NOUN'},\n",
    "           {'LOWER': 'such'},\n",
    "           {'LOWER': 'as'},\n",
    "           {'POS': 'PROPN'}]\n",
    "\n",
    "matcher.add(\"matching_1\", None, pattern)\n",
    "matches = matcher(doc)\n",
    "\n",
    "span = doc[matches[0][1]:matches[0][2]]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, “developing countries” is the hypernym and “Vietnam” is the hyponym. Both of them are semantically related.\n",
    "\n",
    "Note: The key ‘OP’: ‘?’ in the pattern above means that the modifier (‘amod’) can occur once or not at all.\n",
    "\n",
    "In a similar manner, we can get several pairs from any piece of text:\n",
    "\n",
    "    Fruits such as apples\n",
    "    Cars such as Ferrari\n",
    "    Flowers such as rose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use some other Hearst Patterns to extract more hypernyms and hyponyms.\n",
    "\n",
    "    Pattern: X and/or Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Here --> advmod --> ADV\nis --> ROOT --> AUX\nhow --> advmod --> ADV\nyou --> nsubj --> PRON\ncan --> aux --> VERB\nkeep --> ccomp --> VERB\nyour --> poss --> DET\ncar --> dobj --> NOUN\nand --> cc --> CCONJ\nother --> amod --> ADJ\nvehicles --> conj --> NOUN\nclean --> oprd --> ADJ\n. --> punct --> PUNCT\n"
    }
   ],
   "source": [
    "doc = nlp(\"Here is how you can keep your car and other vehicles clean.\") \n",
    "\n",
    "# print dependency tags and POS tags\n",
    "for tok in doc: \n",
    "  print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "car and other vehicles\n"
    }
   ],
   "source": [
    "# Matcher class object \n",
    "matcher = Matcher(nlp.vocab) \n",
    "\n",
    "#define the pattern \n",
    "pattern = [{'DEP':'amod', 'OP':\"?\"}, \n",
    "           {'POS':'NOUN'}, \n",
    "           {'LOWER': 'and', 'OP':\"?\"}, \n",
    "           {'LOWER': 'or', 'OP':\"?\"}, \n",
    "           {'LOWER': 'other'}, \n",
    "           {'POS': 'NOUN'}] \n",
    "           \n",
    "matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "matches = matcher(doc) \n",
    "span = doc[matches[0][1]:matches[0][2]] \n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try out the same code to capture the “X or Y” pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Here is how you can keep your car or other vehicles clean.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "car or other vehicles\n"
    }
   ],
   "source": [
    "span = doc[matches[0][1]:matches[0][2]] \n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern: X, including Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Eight --> nummod --> NUM\npeople --> nsubjpass --> NOUN\n, --> punct --> PUNCT\nincluding --> prep --> VERB\ntwo --> nummod --> NUM\nchildren --> pobj --> NOUN\n, --> punct --> PUNCT\nwere --> auxpass --> AUX\ninjured --> ROOT --> VERB\nin --> prep --> ADP\nthe --> det --> DET\nexplosion --> pobj --> NOUN\n"
    }
   ],
   "source": [
    "doc = nlp(\"Eight people, including two children, were injured in the explosion\") \n",
    "\n",
    "for tok in doc: \n",
    "  print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Eight people, including two children\n"
    }
   ],
   "source": [
    "# Matcher class object \n",
    "matcher = Matcher(nlp.vocab) \n",
    "\n",
    "#define the pattern \n",
    "pattern = [{'DEP':'nummod','OP':\"?\"}, # numeric modifier \n",
    "           {'DEP':'amod','OP':\"?\"}, # adjectival modifier \n",
    "           {'POS':'NOUN'}, \n",
    "           {'IS_PUNCT': True}, \n",
    "           {'LOWER': 'including'}, \n",
    "           {'DEP':'nummod','OP':\"?\"}, \n",
    "           {'DEP':'amod','OP':\"?\"}, \n",
    "           {'POS':'NOUN'}] \n",
    "                               \n",
    "matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "matches = matcher(doc) \n",
    "span = doc[matches[0][1]:matches[0][2]] \n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern: X, especially Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "A det DET\nhealthy amod ADJ\neating amod VERB\npattern nsubj NOUN\nincludes ROOT VERB\nfruits dobj NOUN\n, punct PUNCT\nespecially advmod ADV\nwhole amod ADJ\nfruits appos NOUN\n. punct PUNCT\n"
    }
   ],
   "source": [
    "doc = nlp(\"A healthy eating pattern includes fruits, especially whole fruits.\")\n",
    "\n",
    "for tok in doc: \n",
    "  print(tok.text, tok.dep_, tok.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "fruits, especially whole fruits\n"
    }
   ],
   "source": [
    "# Matcher class object \n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "#define the pattern \n",
    "pattern = [{'DEP':'nummod','OP':\"?\"}, \n",
    "           {'DEP':'amod','OP':\"?\"}, \n",
    "           {'POS':'NOUN'}, \n",
    "           {'IS_PUNCT':True}, \n",
    "           {'LOWER': 'especially'}, \n",
    "           {'DEP':'nummod','OP':\"?\"}, \n",
    "           {'DEP':'amod','OP':\"?\"}, \n",
    "           {'POS':'NOUN'}] \n",
    "           \n",
    "matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "matches = matcher(doc) \n",
    "span = doc[matches[0][1]:matches[0][2]] \n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtree Matching for Relation Extraction\n",
    "\n",
    "The simple rule-based methods work well for information extraction tasks. However, they have a few drawbacks and shortcomings.\n",
    "\n",
    "We have to be extremely creative to come up with new rules to capture different patterns. It is difficult to build patterns that generalize well across different sentences.\n",
    "\n",
    "To enhance the rule-based methods for relation/information extraction, we should try to understand the dependency structure of the sentences at hand.\n",
    "\n",
    "Let’s take a sample text and build its dependency graphing tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8d8d01838461440f994ef0ab272b37f4-0\" class=\"displacy\" width=\"1100\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Tableau</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">was</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">recently</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">acquired</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">by</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Salesforce.</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-8d8d01838461440f994ef0ab272b37f4-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-8d8d01838461440f994ef0ab272b37f4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-8d8d01838461440f994ef0ab272b37f4-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-8d8d01838461440f994ef0ab272b37f4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-8d8d01838461440f994ef0ab272b37f4-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-8d8d01838461440f994ef0ab272b37f4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-8d8d01838461440f994ef0ab272b37f4-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-8d8d01838461440f994ef0ab272b37f4-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-8d8d01838461440f994ef0ab272b37f4-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-8d8d01838461440f994ef0ab272b37f4-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n</g>\n</svg>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "text = \"Tableau was recently acquired by Salesforce.\" \n",
    "\n",
    "# Plot the dependency graph \n",
    "doc = nlp(text) \n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you find any interesting relation in this sentence?\n",
    "\n",
    "If you look at the entities in the sentence – Tableau and Salesforce – they are related by the term ‘acquired’. So, the pattern I can extract from this sentence is either “Salesforce acquired Tableau” or “X acquired Y”.\n",
    "\n",
    "Now consider this statement: “Careem, a ride-hailing major in the middle east, was acquired by Uber.”\n",
    "\n",
    "Its dependency graph will look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"85f998ea407c41c8a9223c026a6771c5-0\" class=\"displacy\" width=\"2325\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Careem,</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">a</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">ride-</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">hailing</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">major</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">in</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">middle</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">east,</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">was</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">AUX</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">acquired</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">by</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">Uber.</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PROPN</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,2.0 1800.0,2.0 1800.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,177.0 740.0,177.0 740.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,352.0 555.0,352.0 555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-4\" stroke-width=\"2px\" d=\"M70,439.5 C70,89.5 745.0,89.5 745.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M745.0,441.5 L753.0,429.5 737.0,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-5\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M905.0,441.5 L913.0,429.5 897.0,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-6\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,264.5 1435.0,264.5 1435.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-7\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-8\" stroke-width=\"2px\" d=\"M945,439.5 C945,177.0 1440.0,177.0 1440.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1440.0,441.5 L1448.0,429.5 1432.0,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-9\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-10\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1955.0,441.5 L1963.0,429.5 1947.0,429.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-85f998ea407c41c8a9223c026a6771c5-0-11\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-85f998ea407c41c8a9223c026a6771c5-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2130.0,441.5 L2138.0,429.5 2122.0,429.5\" fill=\"currentColor\"/>\n</g>\n</svg>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "text= \"Careem, a ride-hailing major in the middle east, was acquired by Uber.\"\n",
    "doc = nlp(text) \n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty scary, right?\n",
    "\n",
    "Don’t worry! All we have to check is which dependency paths are common between multiple sentences. This method is known as Subtree matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will just consider the common dependency paths and extract the entities and the relation (acquired) between them. Hence, the relations extracted from these sentences are:\n",
    "\n",
    "    Salesforce acquired Tableau\n",
    "    Uber acquired Careem\n",
    "\n",
    "Let’s try to implement this technique in Python. We will again use spaCy as it makes it pretty easy to traverse a dependency tree.\n",
    "\n",
    "We will start by taking a look at the dependency tags and POS tags of the words in the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tableau --> nsubjpass --> PROPN\nwas --> auxpass --> AUX\nrecently --> advmod --> ADV\nacquired --> ROOT --> VERB\nby --> agent --> ADP\nSalesforce --> pobj --> PROPN\n. --> punct --> PUNCT\n"
    }
   ],
   "source": [
    "text = \"Tableau was recently acquired by Salesforce.\" \n",
    "doc = nlp(text) \n",
    "\n",
    "for tok in doc: \n",
    "  print(tok.text,\"-->\",tok.dep_,\"-->\",tok.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dependency tag for “Tableau” is nsubjpass which stands for a passive subject (as it is a passive sentence). The other entity “Salesforce” is the object in this sentence and the term “acquired” is the ROOT of the sentence which means it somehow connects the object and the subject.\n",
    "\n",
    "Let’s define a function to perform subtree matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_matcher(doc): \n",
    "  x = '' \n",
    "  y = '' \n",
    "  \n",
    "  # iterate through all the tokens in the input sentence \n",
    "  for i,tok in enumerate(doc): \n",
    "    # extract subject \n",
    "    if tok.dep_.find(\"subjpass\") == True: \n",
    "      y = tok.text \n",
    "      \n",
    "    # extract object \n",
    "    if tok.dep_.endswith(\"obj\") == True: \n",
    "      x = tok.text \n",
    "      \n",
    "  return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we just have to find all those sentences that:\n",
    "\n",
    "    Have two entities, and\n",
    "    The term “acquired” as the only ROOT in the sentence\n",
    "\n",
    "We can then capture the subject and the object from the sentences. Let’s call the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Salesforce', 'Tableau')"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "subtree_matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the subject is the acquirer and the object is the entity that is getting acquired. Let’s use the same function, subtree_matcher( ), to extract entities related by the same relation (“acquired”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Uber', 'Careem')"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "text_2 = \"Careem, a ride hailing major in middle east, was acquired by Uber.\" \n",
    "\n",
    "doc_2 = nlp(text_2) \n",
    "subtree_matcher(doc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you see what happened here? This sentence had more words and punctuation marks but still, our logic worked and successfully extracted the related entities.\n",
    "\n",
    "But wait – what if I change the sentence from passive to active voice? Will our logic still work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Tableau', '')"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "text_3 = \"Salesforce recently acquired Tableau.\" \n",
    "doc_3 = nlp(text_3) \n",
    "subtree_matcher(doc_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s not quite what we expected. The function has failed to capture ‘Salesforce’ and wrongly returned ‘Tableau’ as the acquirer.\n",
    "\n",
    "So, what could go wrong? Let’s understand the dependency tree of this sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Salesforce --> nsubj --> NOUN\nrecently --> advmod --> ADV\nacquired --> ROOT --> VERB\nTableau --> dobj --> PROPN\n. --> punct --> PUNCT\n"
    }
   ],
   "source": [
    "for tok in doc_3:    \n",
    "  print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the grammatical functions (subject and object) of the terms ‘Salesforce’ and ‘Tableau’ have been interchanged in the active voice. However, now the dependency tag for the subject has changed to ‘nsubj’ from ‘nsubjpass’. This tag indicates that the sentence is in the active voice.\n",
    "\n",
    "We can use this property to modify our subtree matching function. Given below is the new function for subtree matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_subtree_matcher(doc):\n",
    "  subjpass = 0\n",
    "\n",
    "  for i,tok in enumerate(doc):\n",
    "    # find dependency tag that contains the text \"subjpass\"    \n",
    "    if tok.dep_.find(\"subjpass\") == True:\n",
    "      subjpass = 1\n",
    "\n",
    "  x = ''\n",
    "  y = ''\n",
    "\n",
    "  # if subjpass == 1 then sentence is passive\n",
    "  if subjpass == 1:\n",
    "    for i,tok in enumerate(doc):\n",
    "      if tok.dep_.find(\"subjpass\") == True:\n",
    "        y = tok.text\n",
    "\n",
    "      if tok.dep_.endswith(\"obj\") == True:\n",
    "        x = tok.text\n",
    "  \n",
    "  # if subjpass == 0 then sentence is not passive\n",
    "  else:\n",
    "    for i,tok in enumerate(doc):\n",
    "      if tok.dep_.endswith(\"subj\") == True:\n",
    "        x = tok.text\n",
    "\n",
    "      if tok.dep_.endswith(\"obj\") == True:\n",
    "        y = tok.text\n",
    "\n",
    "  return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try this new function on the active voice sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Salesforce', 'Tableau')"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "new_subtree_matcher(doc_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The output is correct. Let’s pass the previous passive sentence to this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Salesforce', 'Tableau')"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "new_subtree_matcher(nlp(\"Tableau was recently acquired by Salesforce.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s exactly what we were looking for. We have made the function slightly more general. I would urge you to deep dive into the grammatical structure of different types of sentences and try to make this function more flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End Notes\n",
    "\n",
    "In this article, we learned about Information Extraction, the concept of relations and triples, and different methods for relation extraction. Personally, I really enjoyed doing research on this topic and am planning to write a few more articles on more advanced methods for information extraction.\n",
    "\n",
    "Although we have covered a lot of ground, we have just scratched the surface of the field of Information Extraction. The next step is to use the techniques learned in this article on a real-world text dataset and see how effective these methods are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}