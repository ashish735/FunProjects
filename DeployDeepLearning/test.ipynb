{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize dataset into a useful structure\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "# create directories\n",
    "dataset_home = 'dataset_dogs_vs_cats/'\n",
    "subdirs = ['train/', 'test/']\n",
    "for subdir in subdirs:\n",
    "\t# create label subdirectories\n",
    "\tlabeldirs = ['dogs/', 'cats/']\n",
    "\tfor labldir in labeldirs:\n",
    "\t\tnewdir = dataset_home + subdir + labldir\n",
    "\t\tmakedirs(newdir, exist_ok=True)\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# define ratio of pictures to use for validation\n",
    "val_ratio = 0.25\n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = 'train/'\n",
    "for file in listdir(src_directory):\n",
    "\tsrc = src_directory + '/' + file\n",
    "\tdst_dir = 'train/'\n",
    "\tif random() < val_ratio:\n",
    "\t\tdst_dir = 'test/'\n",
    "\tif file.startswith('cat'):\n",
    "\t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
    "\t\tcopyfile(src, dst)\n",
    "\telif file.startswith('dog'):\n",
    "\t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "\t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(1, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t# specify imagenet mean values for centering\n",
    "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterator\n",
    "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "    model.save('final_model.h5')\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[<tf.Tensor 'dense_8/Identity:0' shape=(None, 1) dtype=float32>]\n"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('final_model.h5')\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[<tf.Tensor 'input_3:0' shape=(None, 224, 224, 3) dtype=float32>]\n"
    }
   ],
   "source": [
    "print(model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dog\n"
    }
   ],
   "source": [
    "# make a prediction for a new image.\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(224, 224))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 224, 224, 3)\n",
    "\t# center pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img - [123.68, 116.779, 103.939]\n",
    "\treturn img\n",
    "\n",
    "# load an image and predict the class\n",
    "\n",
    "# load the image\n",
    "img = load_image('golden-retriever-royalty-free-image-506756303-1560962726.jpg')\n",
    "# load model\n",
    "model = load_model('final_model.h5')\n",
    "# predict the class\n",
    "result = model.predict(img)\n",
    "#print(result[0])\n",
    "if(result[0]==0):\n",
    "    print('Cat')\n",
    "else:\n",
    "    print('Dog')\n",
    "\n",
    "# entry point, run the example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From D:\\ProjectsEnv\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: my_model2\\assets\n"
    }
   ],
   "source": [
    "model.save('my_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: my_model3\\assets\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.saved_model.save(model, \"my_model3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['serving_default']\n"
    }
   ],
   "source": [
    "loaded = tf.saved_model.load(\"my_model3\")\n",
    "print(list(loaded.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'dense_8': TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_8')}\n"
    }
   ],
   "source": [
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The given SavedModel SignatureDef contains the following input(s):\n  inputs['mobilenetv2_1.00_128_input'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 128, 128, 3)\n      name: serving_default_mobilenetv2_1.00_128_input:0\nThe given SavedModel SignatureDef contains the following output(s):\n  outputs['dense'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 1)\n      name: StatefulPartitionedCall:0\nMethod name is: tensorflow/serving/predict\n2020-06-01 10:49:59.564034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\n"
    }
   ],
   "source": [
    "! saved_model_cli show --dir pets --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The given SavedModel SignatureDef contains the following input(s):\n  inputs['image_tensor'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 224, 224, 3)\n      name: similarity_image_tensor:0\nThe given SavedModel SignatureDef contains the following output(s):\n  outputs['output_0'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 1)\n      name: StatefulPartitionedCall:0\nMethod name is: tensorflow/serving/predict\n"
    }
   ],
   "source": [
    "! saved_model_cli show --dir custom_sig --tag_set serve --signature_def similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The given SavedModel SignatureDef contains the following input(s):\n  inputs['input_3'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 224, 224, 3)\n      name: serving_default_input_3:0\nThe given SavedModel SignatureDef contains the following output(s):\n  outputs['dense_8'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 1)\n      name: StatefulPartitionedCall:0\nMethod name is: tensorflow/serving/predict\n2020-06-01 10:46:01.319710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\n"
    }
   ],
   "source": [
    "! saved_model_cli show --dir my_model3 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 224, 224, 3)\n(1, 1, 224, 224, 3)\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img = load_image('golden-retriever-royalty-free-image-506756303-1560962726.jpg')\n",
    "#img=np.expand_dims(img, axis=0)\n",
    "print(img.shape)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "print(img.shape)\n",
    "img = img.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = load_image('golden-retriever-royalty-free-image-506756303-1560962726.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1, 224, 224, 3)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "img=np.reshape(img, (-1,224,224,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('img',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! saved_model_cli run --dir my_model3 --tag_set serve --signature_def serving_default --inputs \"input_3=img.npy\" --outdir model_cli_run_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/matterport/Mask_RCNN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/content/Mask_RCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/experiencor/kangaroo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Model with Custom Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: custom_sig\\assets\n"
    }
   ],
   "source": [
    "class CustomSig(tf.Module):\n",
    "    def __init__(self,model):\n",
    "        super(CustomSig, self).__init__()\n",
    "        self.model=model\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self,image_tensor):\n",
    "        return self.model(image_tensor)     \n",
    "\n",
    "modul = CustomSig(model)\n",
    "\n",
    "signatures = {\"similarity\": modul.__call__.get_concrete_function(tf.TensorSpec(shape=(None,224,224,3), dtype=tf.float32))}\n",
    "\n",
    "tf.saved_model.save(modul, \"custom_sig\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing the signature keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.saved_model.load(\"custom_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['similarity']"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "list(m.signatures.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.1.0'"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model with intermediate layer as Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 25088)             0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 128)               3211392   \n_________________________________________________________________\ndense_8 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 17,926,209\nTrainable params: 3,211,521\nNon-trainable params: 14,714,688\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "mid_output = model.get_layer('dense_7').output\n",
    "image_input = model.get_layer('input_3').output\n",
    "#image_input = Input(shape=(None,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'dense_7_1/Identity:0' shape=(None, 128) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "mid_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'input_3_1:0' shape=(None, 224, 224, 3) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Model(inputs=image_input, outputs=mid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From D:\\ProjectsEnv\\Stan\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: custom_sig\\assets\n"
    }
   ],
   "source": [
    "class CustomSig(tf.Module):\n",
    "    def __init__(self,model):\n",
    "        super(CustomSig, self).__init__()\n",
    "        self.model=model\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self,image_tensor):\n",
    "        return self.model(image_tensor)     \n",
    "\n",
    "modul = CustomSig(final_model)\n",
    "\n",
    "signatures = {\"similarity\": modul.__call__.get_concrete_function(tf.TensorSpec(shape=(None,224,224,3), dtype=tf.float32))}\n",
    "\n",
    "tf.saved_model.save(modul, \"custom_sig\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The given SavedModel SignatureDef contains the following input(s):\n  inputs['image_tensor'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 224, 224, 3)\n      name: similarity_image_tensor:0\nThe given SavedModel SignatureDef contains the following output(s):\n  outputs['output_0'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 128)\n      name: StatefulPartitionedCall:0\nMethod name is: tensorflow/serving/predict\n"
    }
   ],
   "source": [
    "! saved_model_cli show --dir custom_sig --tag_set serve --signature_def similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! saved_model_cli run --dir custom_sig --tag_set serve --signature_def similarity --inputs \"image_tensor=img.npy\" --outdir model_cli_run_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model with a given output name and multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "mid_output = model.get_layer('dense_7').output\n",
    "image_input = model.get_layer('input_3').output\n",
    "final_model = Model(inputs=image_input, outputs=mid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: custom_sig\\assets\n"
    }
   ],
   "source": [
    "class CustomSig(tf.Module):\n",
    "    def __init__(self,model,final_model):\n",
    "        super(CustomSig, self).__init__()\n",
    "        self.model=model\n",
    "        self.final_model=final_model\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self,image_tensor):\n",
    "        return {'output_tensor': self.model(image_tensor),\n",
    "                'intermediate_output':self.final_model(image_tensor)}     \n",
    "\n",
    "modul = CustomSig(model, final_model)\n",
    "\n",
    "signatures = {\"similarity\": modul.__call__.get_concrete_function(tf.TensorSpec(shape=(None,224,224,3), dtype=tf.float32))}\n",
    "\n",
    "tf.saved_model.save(modul, \"custom_sig\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The given SavedModel SignatureDef contains the following input(s):\n  inputs['image_tensor'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 224, 224, 3)\n      name: similarity_image_tensor:0\nThe given SavedModel SignatureDef contains the following output(s):\n  outputs['intermediate_output'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 128)\n      name: StatefulPartitionedCall:0\n  outputs['output_tensor'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 1)\n      name: StatefulPartitionedCall:1\nMethod name is: tensorflow/serving/predict\n"
    }
   ],
   "source": [
    "! saved_model_cli show --dir custom_sig --tag_set serve --signature_def similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search for a file in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_files(filename, search_path):\n",
    "   result = []\n",
    "\n",
    "# Wlaking top-down from the root\n",
    "   for root, dir, files in os.walk(search_path):\n",
    "      if filename in files:\n",
    "         result.append(os.path.join(root, filename))\n",
    "   return result\n",
    "\n",
    "print(find_files(\"smpl.htm\",\"D:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train=[]\n",
    "for root, directory, files in os.walk(search_path):\n",
    "    z = list(set(files).intersection(train_files))\n",
    "    if(len(z)>0):\n",
    "        for i in z:\n",
    "            result_train.append(os.path.join(root,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gRPC request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel('localhost:8500')\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = 'my_model'\n",
    "request.model_spec.signature_name = 'similarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path ='bengal_cat.jpg'\n",
    "\n",
    "image = load_img(image_path, target_size=(128, 128))\n",
    "\t# convert to array\n",
    "image = img_to_array(image)\n",
    "# reshape into a single sample with 3 channels\n",
    "image = image.reshape(1, 128, 128, 3)\n",
    "# center pixel data\n",
    "image = image.astype('float32')\n",
    "#image = image - [123.68, 116.779, 103.939]\n",
    "final_image.extend(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path ='golden-retriever-royalty-free-image-506756303-1560962726.jpg'\n",
    "\n",
    "image = load_img(image_path, target_size=(128, 128))\n",
    "\t# convert to array\n",
    "image = img_to_array(image)\n",
    "# reshape into a single sample with 3 channels\n",
    "image = image.reshape(1, 128, 128, 3)\n",
    "# center pixel data\n",
    "image = image.astype('float32')\n",
    "#image = image - [123.68, 116.779, 103.939]\n",
    "final_image.extend(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(numpy.ndarray, numpy.ndarray)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "final_image = numpy.array(final_image) \n",
    "type(final_image),type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2, 128, 128, 3)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "final_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "final_image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.inputs['images'].CopyFrom(tf.make_tensor_proto(final_image, shape=[final_image.shape[0],128,128,3]))\n",
    "result = stub.Predict(request, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensorflow_serving.apis.predict_pb2.PredictResponse"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(400,)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "floats = numpy.array(list(result.outputs['image_vectors'].float_val))\n",
    "floats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_float=numpy.split(floats,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_float=numpy.array(image_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2, 200)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "image_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cat \nDog \n"
    }
   ],
   "source": [
    "for i in floats:\n",
    "    if(i>0.5):\n",
    "        print('Dog ')\n",
    "    else:\n",
    "        print('Cat ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any Shape Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(None,None,3))\n",
    "y = Reshape((1,))(x)\n",
    "model_any_shape_input = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_14 (InputLayer)        [(None, None, None, 3)]   0         \n_________________________________________________________________\nreshape_5 (Reshape)          (None, 1)                 0         \n=================================================================\nTotal params: 0\nTrainable params: 0\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model_any_shape_input.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: any_input\\assets\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.saved_model.save(model_any_shape_input, \"any_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The given SavedModel SignatureDef contains the following input(s):\n  inputs['input_14'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, -1, -1, 3)\n      name: serving_default_input_14:0\nThe given SavedModel SignatureDef contains the following output(s):\n  outputs['reshape_5'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 1)\n      name: PartitionedCall:0\nMethod name is: tensorflow/serving/predict\n2020-06-11 17:30:28.867483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\n"
    }
   ],
   "source": [
    "! saved_model_cli show --dir any_input --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the depth of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2, 2)\n[[1 2]\n [3 4]]\n\n[[[1 1 1]\n  [2 2 2]]\n\n [[3 3 3]\n  [4 4 4]]]\n(2, 2, 3)\n"
    }
   ],
   "source": [
    "img = np.array([[1, 2], [3, 4]])\n",
    "print(img.shape)\n",
    "print(img)\n",
    "print()\n",
    "stacked_img = np.stack((img,)*3, axis=-1)\n",
    "print(stacked_img)\n",
    "print(stacked_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2 2 2 2\n"
    }
   ],
   "source": [
    "print(img[0][1], stacked_img[0][1][0], stacked_img[0][1][1], stacked_img[0][1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using REST Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://covid-193.p.rapidapi.com/statistics\"\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"covid-193.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"ed8f7e8cfemshc66d9c7f282bcacp1925c8jsn0d873cee5415\"\n",
    "    }\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitconda7155640d2943434980c0d2fbfddaa455",
   "display_name": "Python 3.7.6 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}